[osuser@bastion epay_deven]$ cat recon-spark-app.yaml
# SparkApplication for ReconSparkAppMain
# This YAML demonstrates how to deploy the recon Spark application

apiVersion: spark.apache.org/v1beta1
kind: SparkApplication
metadata:
  name: recon-spark-app
  namespace: dev-rns
  labels:
    app: recon-spark-main
    version: "0.0.1"
    java-version: "21"
    component: recon
spec:
  deploymentMode: ClusterMode
  mainClass: com.epay.operations.recon.ReconSparkAppMain
  # JAR path in the custom image
  jars: local:///opt/spark/work-dir/recon-spark-job.jar

  runtimeVersions:
    sparkVersion: "4.0.0"

  sparkConf:
    # === CONTAINER CONFIGURATION ===
    # Use custom recon image (build from Dockerfile)
    spark.kubernetes.container.image: registry.dev.sbiepay.sbi:8443/spark/sparkrecon:4.0.0_12092025v20
    spark.kubernetes.container.image.pullPolicy: Always

    # === SECURITY CONFIGURATION ===
    spark.kubernetes.authenticate.driver.serviceAccountName: spark-sa
    spark.kubernetes.executor.serviceAccount: spark-sa

    # === RESOURCE CONFIGURATION ===
    spark.driver.memory: "2g"
    spark.driver.cores: "2"
    spark.executor.instances: "1"
    spark.executor.memory: "1g"
    spark.executor.cores: "1"
    spark.dynamicAllocation.enabled: "false"

    # === RECON APPLICATION CONFIGURATION ===
    # Environment variables for recon processing
    spark.kubernetes.driver.service.type: ClusterIP
    spark.kubernetes.driver.env.rfId: "1A6CF13C-DF22-4845-A15A-F740E2716015"
    spark.kubernetes.driver.env.callbackUrl: "http://your-ops-service:9097/api/rns/v1/spark/recon-complete-callback"
    spark.kubernetes.driver.env.RECON_MODE: "production"
    spark.kubernetes.driver.env.DATA_SOURCE: "hdfs"
    spark.kubernetes.driver.env.OUTPUT_PATH: "/tmp/recon/output"
    spark.kubernetes.driver.env.LOG_LEVEL: "INFO"

    # === SYSTEM PROPERTIES FOR RECON ===
    spark.driver.extraJavaOptions: >-
      -DrfId=1A6CF13C-DF22-4845-A15A-F740E2716015
      -DcallbackUrl=http://your-ops-service:9097/api/rns/v1/spark/recon-complete-callback
      -DRECON_MODE=production
      -DDATA_SOURCE=hdfs
      -DOUTPUT_PATH=/tmp/recon/output
      -DLOG_LEVEL=INFO
      -XX:+UseG1GC
      -XX:MaxGCPauseMillis=200

    # === EXECUTOR JAVA OPTIONS ===
    spark.executor.extraJavaOptions: >-
      -XX:+UseG1GC
      -XX:MaxGCPauseMillis=200

    # === HADOOP CONFIGURATION ===
    spark.hadoop.security.authentication: "simple"
    spark.kubernetes.kerberos.enabled: "false"

    # === APPLICATION CONFIGURATION ===
    spark.kubernetes.namespace: dev-rns
    spark.app.name: "recon-spark-app"

    # === LOGGING CONFIGURATION ===
    spark.kubernetes.driver.log.maxFiles: "10"
    spark.kubernetes.driver.log.maxSize: "200m"
    spark.kubernetes.executor.log.maxFiles: "10"
    spark.kubernetes.executor.log.maxSize: "200m"

    # === RECON SPECIFIC CONFIGURATION ===
    # Configure Spark for data processing workloads
    spark.sql.adaptive.enabled: "true"
    spark.sql.adaptive.coalescePartitions.enabled: "true"
    spark.sql.adaptive.skewJoin.enabled: "true"
    spark.serializer: "org.apache.spark.serializer.KryoSerializer"
    spark.sql.execution.arrow.pyspark.enabled: "true"
